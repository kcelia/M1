{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, linewidth=320)\n",
    "plt.close('all')\n",
    "alphabet = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(fname):\n",
    "\n",
    "    with open('lettres1.pkl', 'rb') as f:\n",
    "        data = pkl.load(f, encoding='latin1') \n",
    "    X = np.array(data.get('letters')) # récupération des données sur les lettres\n",
    "    Y = np.array(data.get('labels')) # récupération des étiquettes associées \n",
    "    nCl=26\n",
    "    return data,X,Y,nCl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, X, Y, nCl = load_data('lettres1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1 Apprentissage d'un modèle connaissant les états ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hypothèse Gauche-Droite\n",
    "def discretisation( X, n_etats = 10 ) :\n",
    "    intervalle = 360. / n_etats\n",
    "    return np.array([ np.floor( x / intervalle ) for x in X ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#teste\n",
    "xd = discretisation(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothèse Gauche-Droite"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On fait l'hypothèse que les états sont connus... Alors que ce n'est pas le cas. Mais il existe des stratégies simples (et parfois efficaces) pour attribuer arbitrairement des états sur les chaines. La plus classique est l'hypothèse gauche-droite, qui est bien adaptée aux signaux courts et non périodiques: \n",
    "\n",
    "On définit le nombre d'états N \n",
    "On découpe chaque série d'observations en N portions à peu près égales \n",
    "On affecte l'état 0 au début, puis on incrémente jusqu'à l'état N pour la dernière portion de la chaine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_Xd(Xd,N):\n",
    "    return np.floor(np.linspace(0,N-.00000001,len(Xd)))\n",
    "    \n",
    "def initGD(X,N):\n",
    "    return np.array([ seq_Xd(x,N) for x in X ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#teste\n",
    "\n",
    "# 10 etats possibles pour la variable d'observation X\n",
    "# 3  etats possibles pour la variable d'état caché \n",
    "\n",
    "#X0 = [ 1.  9.  8.  8.  8.  8.  8.   9.  3.  4.  5.  6.  6.  6.  7.  7.  8.  9.  0.  0.  0.  1.  1.]\n",
    "#S0 = [ 0.  0.  0.  0.  0.  0.  1.   1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  3.  3.  3.  3.  3.  3.]\n",
    "S= initGD(xd,5)\n",
    "#print(xd[0])\n",
    "#print(S[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #version 2 \n",
    "def learnHMM(x, s, N, K, initTo0=True):\n",
    "    \n",
    "    if np.shape(s) != np.shape(x):\n",
    "        raise Exception(\"Invalid Data\")\n",
    "        \n",
    "    if initTo0:\n",
    "        A  = np.zeros((N,N))\n",
    "        B  = np.zeros((N,K))\n",
    "        Pi = np.zeros(N)\n",
    "    else:\n",
    "        eps = 1e-8\n",
    "        A  = np.ones((N,N))*eps\n",
    "        B  = np.ones((N,K))*eps\n",
    "        Pi = np.ones(N)*eps\n",
    "\n",
    "    for i,ss in enumerate(s):\n",
    "\n",
    "        Pi[int(s[i][0])] += 1\n",
    "        \n",
    "    for i in range(len(s)):\n",
    "        for j in range(1,len(s[i])):\n",
    "            A[int(s[i][j-1])][int(s[i][j])] += 1\n",
    "            \n",
    "    for ss,xx in zip(s,x):\n",
    "        for i,j in zip(ss,xx):\n",
    "            B[int(i)][int(j)] +=1\n",
    "            \n",
    "    A /= np.maximum(A.sum(1).reshape(N,1),1)\n",
    "    B /= np.maximum(B.sum(1).reshape(N,1),1)\n",
    "    Pi/= Pi.sum()\n",
    "\n",
    "    return ( Pi, A, B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.]\n",
      "[[ 0.79  0.21  0.    0.    0.  ]\n",
      " [ 0.    0.76  0.24  0.    0.  ]\n",
      " [ 0.    0.    0.77  0.23  0.  ]\n",
      " [ 0.    0.    0.    0.76  0.24]\n",
      " [ 0.    0.    0.    0.    1.  ]]\n",
      "[[ 0.06  0.02  0.    0.    0.    0.    0.    0.04  0.49  0.4 ]\n",
      " [ 0.    0.04  0.    0.13  0.09  0.13  0.02  0.09  0.41  0.09]\n",
      " [ 0.    0.    0.    0.02  0.12  0.5   0.31  0.04  0.    0.  ]\n",
      " [ 0.07  0.    0.    0.    0.    0.    0.26  0.33  0.2   0.15]\n",
      " [ 0.73  0.12  0.    0.    0.    0.    0.    0.02  0.02  0.12]]\n"
     ]
    }
   ],
   "source": [
    "#teste\n",
    "K = 10 # discrétisation (=10 observations possibles)\n",
    "N = 5  # 5 états possibles (de 0 à 4 en python) \n",
    "Pi, A, B = learnHMM(xd[Y=='a'],S[Y=='a'],N,K)\n",
    "print(Pi)\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Viterbi (en log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  9.,  8.,  8.,  8.,  8.,  8.,  9.,  3.,  4.,  5.,  6.,  6.,  6.,  7.,  7.,  8.,  9.,  0.,  0.,  0.,  1.,  1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Viterbi sert à\n",
    "1. estimer la séquence d'états la plus probable étant donnés les observations et le modèle. \n",
    "2. peut servir à approximer la probabilité de la séquence d'observation étant donné le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi(O, Pi, A, B):\n",
    "    \n",
    "    #rappel : la fonction argmax returne l'indice de l'element max dans un tableau depuis l'axis \n",
    "    \n",
    "   \n",
    "    delta = np.zeros((len(A), len(O)))\n",
    "    psi   = np.zeros((len(A), len(O)))\n",
    "\n",
    "    # initialisation\n",
    "    #formule du cours \n",
    "    # δ0(i) = πi . bi(x0) on passe au log:   long(πi) +log(bi(O(0)))\n",
    "    # Ψ0(i) = −1 Note: -1 car non utilisé normalement\n",
    "    \n",
    "    #B[:,int(O[0])] renvoit la colonne correspondante a la valeur de O[0]\n",
    "    # O[0] pour la sequence x vaut 1 donc la colonne selectionnée est la colonne 1 \n",
    "    \n",
    "    \n",
    "    delta[:, 0] = np.log(B[:, int(O[0])]) + np.log(Pi)\n",
    "    psi[:, 0] = -1\n",
    "\n",
    "    \n",
    "    # Recursion\n",
    "    #δt(j) = [maxiδt−1(i)+log aij ]+log bj(xt)\n",
    "    #Ψt(j) = arg max i∈[1, N] δt−1(i)+log aij\n",
    "    \n",
    "    for t in range(1, len(O)):\n",
    "        for j in range(len(A)):\n",
    "            tmp = delta[:, int(t-1)] + np.log(A[:, j])\n",
    "            delta[j, t] = max(tmp) + np.log(B[j, int(O[t])])\n",
    "            psi[j, t] = np.argmax(tmp)\n",
    "\n",
    "    # Termination\n",
    "    #S⋆=maxiδT−1(i)\n",
    "    \n",
    "    S = max(delta[:, -1])\n",
    "\n",
    "    # Path\n",
    "    #s⋆T−1 = arg max i δT−1(i)\n",
    "    #s⋆t   = Ψt+1 (s⋆t+1)\n",
    "    \n",
    "    T = len(O)\n",
    "    s = [0] * T\n",
    "    s[T - 1] = np.argmax(delta[:, int(t)])\n",
    "    for t in range(T - 2, 1, - 1):\n",
    "        s[t] = psi[:, int(t + 1)][int(s[t + 1])]\n",
    "\n",
    "    return np.int64(s), S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kherf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\kherf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\kherf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#teste\n",
    "\n",
    "path,proba = viterbi(xd[0],Pi,A,B)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OPT] Probabilité d'une séquence d'observation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En fonction de votre vitesse d'avancement, coder la version α\n",
    "de l'estimation (exacte) des probabilités d'une séquence d'observations. \n",
    "        Comparer avec l'approximation estimée précédemment (le résultat attendu est-il plus ou moins élevé avec la procédure exacte?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02  -inf   nan ...,  0.    0.    0.  ]\n",
      " [ 0.    -inf   nan ...,  0.    0.    0.  ]\n",
      " [ 0.    -inf   nan ...,  0.    0.    0.  ]\n",
      " [ 0.    -inf   nan ...,  0.    0.    0.  ]\n",
      " [ 0.     nan   nan ...,  0.    0.    0.  ]]\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kherf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\kherf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\kherf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\kherf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "def methode_alpha(x,Pi,A,B):\n",
    "\n",
    "    mat = np.zeros((len(A),len(X)))\n",
    "   \n",
    "    for i in range(len(mat)):\n",
    "        mat[i][0] = Pi[i] * B[i][int(x[0])]\n",
    "\n",
    "    for t in range(1,len(x)):\n",
    "        for j in range(len(A)):\n",
    "            tmp=0\n",
    "            for i in range(len(A)):\n",
    "                tmp += np.log(mat[i][t-1]) * np.log(A[i][j])\n",
    "               # print(np.log(tmp))\n",
    "            tmp = tmp * np.log(B[j][int(x[t])])\n",
    "            #print(tmp)\n",
    "            mat[j][t] = tmp\n",
    "    \n",
    "    proba = np.sum(mat[:,-1])\n",
    "    \n",
    "    print(mat)\n",
    "    print(proba)\n",
    "\n",
    "methode_alpha(xd[0],Pi,A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0188679245283\n",
      "[[  1.89e-02   3.14e-01   3.68e-01   3.07e-01   2.71e-01   2.47e-01   2.31e-01   1.77e-01   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00]\n",
      " [  0.00e+00   1.80e-02   9.81e-02   1.34e-01   1.55e-01   1.69e-01   1.79e-01   3.90e-02   4.01e-02   6.47e-02   6.69e-02   4.05e-03   2.68e-04   1.59e-05   3.91e-06   1.60e-06   2.16e-06   9.60e-07   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00]\n",
      " [  0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   9.00e-04   3.13e-02   2.06e-01   2.00e-01   1.95e-01   1.68e-01   2.00e-02   3.98e-03   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00]\n",
      " [  0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   4.52e-02   8.39e-02   1.01e-01   1.40e-01   2.24e-01   1.44e-01   1.12e-01   3.90e-02   5.83e-03   4.31e-04   0.00e+00   0.00e+00]\n",
      " [  0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   1.73e-03   4.19e-03   4.78e-03   3.04e-02   2.93e-01   6.65e-01   7.26e-01   1.15e-01   1.15e-01]]\n",
      "[-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kherf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "def methode_alpha(x,Pi,A,B):\n",
    "\n",
    "    mat = np.zeros((len(A),len(x)))\n",
    "   \n",
    "    for i in range(len(mat)):\n",
    "        mat[i][0] = Pi[i] * B[i][int(x[0])]\n",
    "        \n",
    "    print(mat[:, 0].sum())\n",
    "\n",
    "    for t in range(1,len(x)):\n",
    "        for j in range(len(A)):\n",
    "            tmp=0\n",
    "            for i in range(len(A)):\n",
    "                tmp += mat[i][t-1]*A[i][j]*B[j][int(x[t])]\n",
    "               # print(np.log(tmp))\n",
    "             \n",
    "            #print(tmp)\n",
    "            tmp /= np.sum(mat[:,(t-1)])\n",
    "            mat[j][t] = tmp\n",
    "\n",
    "        #print(mat[:,t], (mat[:(t-1)]))\n",
    "    proba = [np.sum(np.log(mat[:,-i]) ) for i in range(len(x))]\n",
    "    for i in range(len(x)):\n",
    "        tmp = np.sum(mat[:,i])\n",
    "    print(mat)\n",
    "    print(proba)\n",
    "\n",
    "methode_alpha(xd[0],Pi,A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.8950422805\n"
     ]
    }
   ],
   "source": [
    "def methode_alpha(x,Pi,A,B):\n",
    "\n",
    "    mat = np.zeros((len(A),len(x)))\n",
    "   \n",
    "    for i in range(len(mat)):\n",
    "        mat[i][0] = Pi[i] * B[i][int(x[0])]\n",
    "        \n",
    "#    print(mat[:, 0].sum())\n",
    "\n",
    "    for t in range(1,len(x)):\n",
    "        for j in range(len(A)):\n",
    "            tmp=0\n",
    "            for i in range(len(A)):\n",
    "                tmp += mat[i][t-1]*A[i][j]*B[j][int(x[t])]\n",
    "               # print(np.log(tmp))\n",
    "             \n",
    "            #print(tmp)\n",
    "            tmp /= np.sum(mat[:,(t-1)])\n",
    "            mat[j][t] = tmp\n",
    "\n",
    "\n",
    "    tmp=0\n",
    "    for i in range(len(x)):\n",
    "        tmp += np.log(np.sum(mat[:,i]))\n",
    "    print(tmp)\n",
    "\n",
    "methode_alpha(xd[0],Pi,A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage complet (Baum-Welch simplifié) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baum_welch_simplifie( lv_lst, X, Y, N = 5, K = 10):\n",
    "    # 1. Initialisation des états cachés arbitraire (eg méthode gauche-droite)\n",
    "    nom_iter = 0\n",
    "    alpha    = []\n",
    "    Xd       = discretisation(X,K)\n",
    "    q        = initGD(X,N)\n",
    "    \n",
    "    # 2. Tant que critère de convergence non atteint\n",
    "    while True:\n",
    "        if ( nom_iter > 2 ) and ( lv_lst[-1] - lv_lst[-2] < 0.0001 ):\n",
    "            break\n",
    "            \n",
    "        lv        = 0\n",
    "        nom_iter += 1\n",
    "        alpha     = []\n",
    "        for lettre in alphabet:\n",
    "            # 1. Apprentissage des modèles\n",
    "            ( Pi, A, B ) = learnHMM( Xd[Y==lettre], q[Y==lettre], N, K)\n",
    "            # print \"nom_iter: %d\"%nom_iter, B\n",
    "            alpha.append((Pi,A,B))\n",
    "            # 2. Estimation des états cachés par Viterbi\n",
    "            for [i] in np.argwhere(Y==lettre):\n",
    "                ( p_est, s_est ) = viterbi(Xd[i],Pi,A,B)\n",
    "                q[i] = s_est\n",
    "                lv  += p_est\n",
    "                \n",
    "        lv_lst.append(lv)\n",
    "                \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traçage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####jai pas encore testé cette fonction \n",
    "\n",
    "def tracer_evolution_vraisemblance(lv_list):\n",
    "    fig = plt.figure()\n",
    "    x = range(len(lv_list))\n",
    "    y = lv_list\n",
    "    plt.plot( x, y )\n",
    "    plt.xlabel(\"Nombre d'Iteration\")\n",
    "    plt.ylabel(\"Log Vraisemblance\")\n",
    "    plt.savefig(\"vraisemblance_regression.png\")\n",
    "    \n",
    "\n",
    "\n",
    "#lv_lst = []\n",
    "#baum_welch_simplifie( lv_lst, X, Y,)\n",
    "#tracer_evolution_vraisemblance(lv_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if t == tt: \n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
