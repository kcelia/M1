{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME7 - Réseaux de neurones : DIY\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes abstraites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def forward(self, y, yhat):\n",
    "        \"\"\" Calcule le cout\n",
    "            :y: vraie classe \n",
    "            :yhat: classe prédite\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def backward(self, y, yhat):\n",
    "        \"\"\" Calcule le gradient du cout\n",
    "            :y: vraie classe \n",
    "            :yhat: classe prédite        \n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.gradient = None\n",
    "    \n",
    "    \n",
    "    def zero_grad(self):\n",
    "        # Annule le gradient\n",
    "        self.gradient = np.zeros(self.gradient.shape)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Calcule la passe forward\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def update_parameters(self, gradient_step):\n",
    "        # Calcule la mise à jour des parametres selon le gradient\n",
    "        # et calcule le pas de gradient_step\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def backward_update_gradient(self, input, delta):\n",
    "        # Met à jour la valeur du gradient\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def backward_delta(self, input, delta):\n",
    "        # Calcule la dérivée de l'erreur\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Module linéaire\n",
    "- Fonction d'activation sigmoÏde (/tanh)\n",
    "- Fonction de coût MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoide(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoide_g(x):\n",
    "    return sigmoide(x)*(1-sigmoide(x))\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def tanh_g(x):\n",
    "    return 1 - np.tan(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Loss):\n",
    "    def forward(self, y, yhat):\n",
    "        return 0.5 * np.sum((yhat - y) ** 2)\n",
    "    \n",
    "    \n",
    "    def backward(self, y, yhat):\n",
    "        # calcule le gradient du cout\n",
    "        return np.sum(yhat - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModuleLineaire(Module):\n",
    "    def __init__(self, N, D, fonc=sigmoide, fonc_g=sigmoide_g):\n",
    "        \"\"\" Paramètres\n",
    "            :N: nombre de neurones\n",
    "            :D: dimensions\n",
    "            :fonc: fonction d'activation\n",
    "            :fonc_g: gradient de la fonction d'activation\n",
    "        \n",
    "        \"\"\"\n",
    "        self.parameters = np.random.random((N, D))\n",
    "        self.gradient = np.zeros(self.parameters.shape)\n",
    "        self.fonc, self.fonc_g = sigmoide, sigmoide_g\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Calcule la passe forward\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        return self.fonc(np.dot(X, self.parameters.T))\n",
    "        \n",
    "        \n",
    "    def update_parameters(self, gradient_step):\n",
    "        # Calcule la mise à jour des parametres selon le gradient\n",
    "        # et le pas de gradient_step\n",
    "        self.parameters += gradient_step * self.gradient\n",
    "            \n",
    "            \n",
    "    def backward_update_gradient(self, input, delta):\n",
    "        # Met à jour la valeur du gradient\n",
    "        if len(input.shape) == 1:\n",
    "            input = input.reshape(1, -1)\n",
    "        res = self.backward_delta(input, delta) * input\n",
    "        self.gradient += res\n",
    "        return res\n",
    "    \n",
    "    \n",
    "    def backward_delta(self, input, delta):\n",
    "        # Calcule la dérivée de l'erreur\n",
    "        return np.sum(delta * \\\n",
    "                     self.parameters.T * self.fonc_g(np.dot(input, self.parameters.T)))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sequentiel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test à la main\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données - générations de gaussiennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arftools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f1263ed37a11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0marftools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;34m\"\"\" Tracer des isocourbes de l'erreur \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mgen_arti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'arftools'"
     ]
    }
   ],
   "source": [
    "from arftools import *\n",
    "\n",
    "\"\"\" Tracer des isocourbes de l'erreur \"\"\"\n",
    "plt.ion()\n",
    "trainx,trainy =  gen_arti(nbex=1000,data_type=1,epsilon=0.5)\n",
    "testx,testy =  gen_arti(nbex=1000,data_type=1,epsilon=0.5)\n",
    "\n",
    "# -------\n",
    "# Construction du RDN\n",
    "cout = MSE()\n",
    "cachee = ModuleLineaire(3, 2)\n",
    "sortie = ModuleLineaire(1, 3)\n",
    "\n",
    "# Apprentissage\n",
    "for i, x in enumerate(trainx):\n",
    "    # forward\n",
    "    z1 = cachee.forward(x)\n",
    "    zs = sortie.forward(z1)\n",
    "    mse = cout.forward(np.sign(zs), trainy[i])\n",
    "    \n",
    "    # backward\n",
    "    mse_g = cout.backward(np.sign(zs), trainy[i])\n",
    "    bs = sortie.backward_update_gradient(z1, mse_g)\n",
    "    sortie.update_parameters(1)\n",
    "    b1 = cachee.backward_update_gradient(x, bs)\n",
    "    cachee.update_parameters(1)\n",
    "\n",
    "# Prediction\n",
    "def predict(datax):\n",
    "    z1 = cachee.forward(datax)\n",
    "    zs = sortie.forward(z1)\n",
    "    return np.sign(zs)\n",
    "\n",
    "def score(datax, datay):\n",
    "    return np.mean(predict(datax) == datay)\n",
    "\n",
    "# --------\n",
    "print(\"Score MSE : train %f, test %f\"% (score(trainx,trainy),score(testx,testy)))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_frontiere(trainx, predict, 200)\n",
    "plot_data(trainx,trainy)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arftools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-eccbb006878d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0marftools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;34m\"\"\" Tracer des isocourbes de l'erreur \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mgen_arti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'arftools'"
     ]
    }
   ],
   "source": [
    "from arftools import *\n",
    "\n",
    "\"\"\" Tracer des isocourbes de l'erreur \"\"\"\n",
    "plt.ion()\n",
    "trainx,trainy =  gen_arti(nbex=1000,data_type=1,epsilon=0.5)\n",
    "testx,testy =  gen_arti(nbex=1000,data_type=1,epsilon=0.5)\n",
    "\n",
    "# -------\n",
    "# Construction du RDN\n",
    "cout = MSE()\n",
    "cachee = ModuleLineaire(3, 2)\n",
    "sortie = ModuleLineaire(1, 3)\n",
    "\n",
    "# Apprentissage\n",
    "# forward\n",
    "z1 = cachee.forward(trainx)\n",
    "zs = sortie.forward(z1)\n",
    "mse = cout.forward(np.sign(zs), trainy[i])\n",
    "\n",
    "# backward\n",
    "mse_g = cout.backward(np.sign(zs), trainy[i])\n",
    "bs = sortie.backward_update_gradient(z1, mse_g)\n",
    "sortie.update_parameters(1)\n",
    "b1 = cachee.backward_update_gradient(trainx, bs)\n",
    "cachee.update_parameters(1)\n",
    "print(mse)\n",
    "\n",
    "# Prediction\n",
    "def predict(datax):\n",
    "    z1 = cachee.forward(datax)\n",
    "    zs = sortie.forward(z1)\n",
    "    return np.sign(zs)\n",
    "\n",
    "def score(datax, datay):\n",
    "    return np.mean(predict(datax) == datay)\n",
    "\n",
    "# --------\n",
    "print(\"Score MSE : train %f, test %f\"% (score(trainx,trainy),score(testx,testy)))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_frontiere(trainx, predict, 200)\n",
    "plot_data(trainx,trainy)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-15-3f6fc65b81c6>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-3f6fc65b81c6>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class Sequentiel:\n",
    "    def __init__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
